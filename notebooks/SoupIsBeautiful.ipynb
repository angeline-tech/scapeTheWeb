{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shared-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def getSoup(url):\n",
    "    html_content = requests.get(url).text\n",
    "    return BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-colon",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "NATIONALITY = ['Nat.','Nationality','Nation']\n",
    "DISCIPLINE = ['Discipline']\n",
    "NAME = ['Player','Name']\n",
    "AGE = ['Age','Date of birth','Pos']\n",
    "YEAR = ['Year']\n",
    "APPS = ['App']\n",
    "GOALS = ['Goal']\n",
    "TEAM = ['Team']\n",
    "MANAGER = ['Manager']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-impression",
   "metadata": {},
   "source": [
    "## File Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sacred-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeagueList(pathToFile):\n",
    "    with open(pathToFile, newline='') as csvfile:\n",
    "        leagues = list(csv.reader(csvfile))\n",
    "    return leagues\n",
    "\n",
    "def writeDataToFile(df,fileName):\n",
    "    df.to_csv('../data/'+fileName,index=False)\n",
    "    print('Writing to ',fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-preference",
   "metadata": {},
   "source": [
    "## String Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "protected-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasElementContaining(array,criteria):\n",
    "    return len(list(filter(lambda x: criteria in x,array))) > 0\n",
    "\n",
    "def hasElementContainingAnyOf(array,criterias):\n",
    "    for criteria in criterias:\n",
    "        if hasElementContaining(array,criteria):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def containsAnyOf(stringToCheck,values):\n",
    "    for value in values:\n",
    "        if value in stringToCheck:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def stripWiki(text):\n",
    "    if text:\n",
    "        return text.replace('/wiki/', '').strip()\n",
    "    return None\n",
    "\n",
    "def fullWiki(text):\n",
    "    return \"https://en.wikipedia.org\" + text\n",
    "\n",
    "def getSquadUrl(url):\n",
    "    return 'https://en.wikipedia.org/wiki/2019-20_'+ url +'_season'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-prime",
   "metadata": {},
   "source": [
    "## Table/Cell Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTables(url):\n",
    "    soup = getSoup(url)\n",
    "    tables = soup.find_all(\"table\", attrs={\"class\": \"wikitable\"})\n",
    "    title = soup.title.text.replace('- Wikipedia', '').strip()\n",
    "    return title,tables\n",
    "\n",
    "def getText(cell):\n",
    "    return cell.text.replace('\\n', '').strip()\n",
    "\n",
    "def getHeaders(table):\n",
    "    return list(map(lambda x:getText(x),table.find_all(\"th\")))\n",
    "\n",
    "def getIndexOf(table,values):\n",
    "    headers = getHeaders(table)\n",
    "    for i in range(len(headers)):\n",
    "        if containsAnyOf(headers[i],values):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def hasNoHeaders(row):\n",
    "        return len(row.find_all(\"th\")) == 0\n",
    "\n",
    "\n",
    "def getRows(table):\n",
    "    return table.tbody.find_all(\"tr\")\n",
    "\n",
    "def getBodyRows(table):\n",
    "    rows = getRows(table)\n",
    "    return list(filter(lambda x: hasNoHeaders(x),rows))\n",
    "\n",
    "def extractLink(link):\n",
    "    return link['href'].strip() if link else None\n",
    "\n",
    "def getTextAndLink(cell):\n",
    "    link = cell.find('a')\n",
    "    url = extractLink(link)\n",
    "    text = getText(cell)\n",
    "    return text,url\n",
    "\n",
    "def getAllLinks(cell):\n",
    "    links = cell.find_all('a')\n",
    "    return list(map(lambda x: (getText(x),extractLink(x)),links))\n",
    "    \n",
    "def getAllCells(row):\n",
    "    cells = row.find_all(\"th\") + row.find_all(\"td\")\n",
    "    return list(map(lambda x:getText(x),cells))\n",
    "\n",
    "def getRowContaining(table,text):\n",
    "    rows = getRows(table)\n",
    "    for row in rows:\n",
    "        cells = getAllCells(row)\n",
    "        if hasElementContaining(cells,text):\n",
    "            return getAllCells(row)\n",
    "    return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-percentage",
   "metadata": {},
   "source": [
    "## Get Appearances For Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enhanced-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInternationalTable(table):\n",
    "    headers = getHeaders(table)\n",
    "    year = hasElementContainingAnyOf(headers,YEAR)\n",
    "    apps = hasElementContainingAnyOf(headers,APPS)\n",
    "    goals = hasElementContainingAnyOf(headers,GOALS)\n",
    "    return year and apps and goals\n",
    "\n",
    "def getAppearancesForPlayer(url):\n",
    "    soup = getSoup(url)\n",
    "    title,tables = getAllTables(url)\n",
    "    internationalTables = list(filter(lambda x: isInternationalTable(x),tables))\n",
    "    if len(internationalTables) > 0:\n",
    "        internationalTable = internationalTables[0]\n",
    "        totalRow = getRowContaining(internationalTable,'Total')\n",
    "        appIndex = getIndexOf(internationalTable,APPS) -1 # Country in First Header\n",
    "        if totalRow:\n",
    "            return totalRow[appIndex]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-lesson",
   "metadata": {},
   "source": [
    "## Get Players from Team Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dying-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPlayerTable(table):\n",
    "    headers = getHeaders(table)\n",
    "    names = hasElementContainingAnyOf(headers,NAME)\n",
    "    nationality = hasElementContainingAnyOf(headers,NATIONALITY) or hasElementContainingAnyOf(headers,DISCIPLINE)\n",
    "    age = hasElementContainingAnyOf(headers,AGE)\n",
    "    notTeam = not hasElementContainingAnyOf(headers,TEAM)\n",
    "    return names and nationality and age and notTeam\n",
    "\n",
    "def getDataFromPlayerTable(playerIndex,countryIndex,rows):\n",
    "    players = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        url = None\n",
    "        country = None\n",
    "        url = None\n",
    "        apps = None\n",
    "        if(playerIndex == -1):\n",
    "            print('ERROR: No Player Index - Stopping Early')\n",
    "            return players\n",
    "        if len(cells) < playerIndex:\n",
    "            print('ERROR: Player Index Greater than Row Length - Stopping Early')\n",
    "            return players\n",
    "        links = getAllLinks(cells[playerIndex])\n",
    "        (name, wikiPrefix) = getTextAndLink(cells[playerIndex])\n",
    "        (tmp, countryWiki) = getTextAndLink(cells[countryIndex])\n",
    "        if len(links) > 0:\n",
    "            country = stripWiki(countryWiki)\n",
    "            url = fullWiki(wikiPrefix)\n",
    "            if countryIndex == -1:\n",
    "#                 print('No Country Column for',name)\n",
    "                emptyLinks = list(filter(lambda x: x[0]=='',links))\n",
    "                if len(emptyLinks) > 0:\n",
    "                    countryLink = emptyLinks[0]\n",
    "                    country = stripWiki(countryLink[1])\n",
    "                urlLinks = list(filter(lambda x: x[0]!='',links))\n",
    "                if len(urlLinks) > 0:\n",
    "                    urlLink = urlLinks[0]\n",
    "                    url = fullWiki(urlLink[1])\n",
    "            apps = getAppearancesForPlayer(url)\n",
    "        else:\n",
    "            print('No links found for',name)\n",
    "        result = (name,country,apps,url)\n",
    "#         print(result)\n",
    "        players.append(result)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regular-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayerDataForTeam(url):\n",
    "    title,tables = getAllTables(url)\n",
    "    print('Starting ',title)\n",
    "    playerTables = list(filter(lambda x: isPlayerTable(x),tables))\n",
    "    if len(playerTables) > 0:\n",
    "        playerTable = playerTables[0]\n",
    "        playerIndex = getIndexOf(playerTable,NAME)\n",
    "        countryIndex = getIndexOf(playerTable,NATIONALITY)\n",
    "        playerRows = getBodyRows(playerTables[0])\n",
    "        if len(playerRows)<17 and len(playerTables)>1:\n",
    "            playerRows = playerRows + getBodyRows(playerTables[1])\n",
    "        return getDataFromPlayerTable(playerIndex,countryIndex,playerRows)\n",
    "    else:\n",
    "        print('Messed Up Getting Players, ',url)\n",
    "        return None\n",
    "# getPlayerDataForTeam('https://en.wikipedia.org/wiki/2019%E2%80%9320_Manchester_United_F.C._season')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-offer",
   "metadata": {},
   "source": [
    "## Get Teams from League Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "undefined-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isTeamsTable(table):\n",
    "    headers = getHeaders(table)\n",
    "    team = hasElementContainingAnyOf(headers,TEAM)\n",
    "    return team \n",
    "\n",
    "def getDataFromTeamTable(table):\n",
    "    rows = getBodyRows(table)\n",
    "    teamIndex = getIndexOf(table,TEAM)\n",
    "    teams = []\n",
    "    dodgy = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\")\n",
    "        team = cells[teamIndex]\n",
    "        (text,prefix) = getTextAndLink(team)\n",
    "        if prefix:\n",
    "            url = getSquadUrl(stripWiki(prefix))\n",
    "            players = getPlayerDataForTeam(url)\n",
    "        else:\n",
    "            print('Something strange happened with: ',text)\n",
    "        if players:\n",
    "            print((text,len(players)))\n",
    "            teams.append((text,len(players),players))\n",
    "        else:\n",
    "            teams.append((text,None,None))\n",
    "            dodgy.append((text,url))\n",
    "    print('Dodgy Teams Were')\n",
    "    print(dodgy)\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fiscal-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTeamsForLeague(url):\n",
    "    title,tables = getAllTables(url)\n",
    "    print(title)\n",
    "    teamTables = list(filter(lambda x: isTeamsTable(x),tables))\n",
    "    if len(teamTables) > 0:\n",
    "        teamTable = teamTables[0]\n",
    "        return getDataFromTeamTable(teamTable)\n",
    "    else:\n",
    "        print('Messed Up Getting Teams, ',url)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-implementation",
   "metadata": {},
   "source": [
    "## Trying for All Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specific-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDf(data):\n",
    "    return pd.DataFrame(data, columns = ['League','Team Name','playerName','country','apps','url']) \n",
    "\n",
    "def formatFlat(rawData):\n",
    "    outputData = []\n",
    "    for league in rawData:\n",
    "        leagueName = league[0]\n",
    "        teamData = league[2]\n",
    "        for team in teamData:\n",
    "            teamName = team[0]\n",
    "            playerCount = team[1]\n",
    "            playerList = team[2]\n",
    "            for player in playerList:\n",
    "                playerName = player[0]\n",
    "                country = player[1]\n",
    "                apps = player[2]\n",
    "                url = player[3]\n",
    "                result = (leagueName,teamName,playerName,country,apps,url)\n",
    "                outputData.append(result)\n",
    "    return outputData\n",
    "            \n",
    "\n",
    "def completedItMate(inputPath,outputDir):\n",
    "    leagues = getLeagueList(inputPath)\n",
    "    rawData = []\n",
    "    for league in leagues:\n",
    "        leagueCountry = league[0]\n",
    "        leagueUrl = league[1]\n",
    "        title,tables = getAllTables(leagueUrl)\n",
    "        rawData.append((title,leagueUrl,getTeamsForLeague(leagueUrl)))\n",
    "        data = formatFlat(rawData)\n",
    "        tmpDf = toDf(data)\n",
    "        writeDatatoFile(tmpDf,outputDir+title+'csv')\n",
    "    formattedData = formatFlat(rawData)\n",
    "    df = toDf(formattedData)\n",
    "    writeDataToFile(df,outputDir+'combined.csv')\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-start",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019–20 La Liga\n",
      "Starting  2019–20 Deportivo Alavés season\n",
      "('Alavés', 26)\n",
      "Starting  2019–20 Athletic Bilbao season\n",
      "No links found for Gaizka Larrazabal\n",
      "No links found for Asier Villalibre\n",
      "No links found for Unai Vencedor\n",
      "No links found for Oihan Sancet\n",
      "('Athletic Bilbao', 4)\n",
      "Starting  2019–20 Atlético Madrid season\n",
      "('Atlético Madrid', 23)\n",
      "Starting  2019–20 FC Barcelona season\n"
     ]
    }
   ],
   "source": [
    "allData = completedItMate('../data/leagues.csv','../bootifulSoupData/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
